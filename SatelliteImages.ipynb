{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, PILToTensor, Resize, Normalize\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "cloudy = './Satellite/cloudy'\n",
    "desert = './Satellite/desert'\n",
    "green = './Satellite/green_area'\n",
    "water = './Satellite/water'\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((256, 256)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Satellite(Dataset):\n",
    "    def __init__(self, folder, label, transform=None):\n",
    "        self.folder = folder\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith('.jpg') or file.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "# dataset\n",
    "cloudy = Satellite(cloudy, label=0, transform=transform)\n",
    "desert = Satellite(desert, label=1, transform=transform)\n",
    "green = Satellite(green, label=2, transform=transform)\n",
    "water = Satellite(water, label=3, transform=transform)\n",
    "\n",
    "# dataloader\n",
    "full_dataset = cloudy + desert+ green+ water\n",
    "train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_height=256, input_width=256):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1_input_size = self._get_flattened_size(input_height, input_width)\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 4)\n",
    "\n",
    "    def _get_flattened_size(self, height, width):\n",
    "        dummy_input = torch.zeros(1, 3, height, width)  # Batch size = 1\n",
    "        x = F.relu(self.bn1(self.conv1(dummy_input)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool(x)\n",
    "        return x.numel() \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)  \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)  \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)  \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)  \n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool(x)  \n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4930134424939752\n",
      "Epoch 2, Loss: 0.4216503955593163\n",
      "Epoch 3, Loss: 0.2869491795480082\n",
      "Epoch 4, Loss: 0.2428474008232694\n",
      "Epoch 5, Loss: 0.17280361543155529\n",
      "Epoch 6, Loss: 0.15955108124762774\n",
      "Epoch 7, Loss: 0.17518840558477677\n",
      "Epoch 8, Loss: 0.1413421927189285\n",
      "Epoch 9, Loss: 0.09944582909850976\n",
      "Epoch 10, Loss: 0.1135892330732366\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 97.80%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
